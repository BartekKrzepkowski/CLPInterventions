{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005f18b-30c2-4b8f-a4e8-8902004c757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad560428-708e-496c-aab6-5e5e75552f74",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba73965-6062-4ac4-a6fb-3e90f62e75bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir=reports --port=6004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6673cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def max_eigenvalue(model, loss_fn, data, target):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Create a variable from the data\n",
    "    data = Variable(data, requires_grad=True)\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(model(data), target)\n",
    "    # Compute the gradients\n",
    "    loss.backward(create_graph=True)\n",
    "    # Get the gradients of the weights\n",
    "    grads = torch.cat([p.grad.view(-1) for p in model.parameters()])\n",
    "    # Create a vector of ones with the same size as the gradients\n",
    "    v = torch.ones(grads.size())\n",
    "    # Compute the Hessian-vector product\n",
    "    Hv = torch.autograd.grad(grads, model.parameters(), grad_outputs=v, retain_graph=True)\n",
    "    # Concatenate the Hessian-vector product into a single vector\n",
    "    Hv = torch.cat([h.view(-1) for h in Hv])\n",
    "    # Compute the maximum eigenvalue using the power iteration method\n",
    "    for _ in range(100):\n",
    "        v = Hv / torch.norm(Hv)\n",
    "        Hv = torch.autograd.grad(grads, model.parameters(), grad_outputs=v, retain_graph=True)\n",
    "        Hv = torch.cat([h.view(-1) for h in Hv])\n",
    "    return (v * Hv).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0420909-6160-4930-8eaa-ddd9b97e919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def max_eigenvalue(model, loss_fn, data, target):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Create a variable from the data\n",
    "    data = torch.autograd.Variable(data, requires_grad=True)\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(model(data), target)\n",
    "    # Compute the gradients\n",
    "    grads = torch.autograd.grad(\n",
    "            loss,\n",
    "            [p for p in model.parameters() if p.requires_grad],\n",
    "            retain_graph=True,\n",
    "            create_graph=True)\n",
    "    # Get the gradients of the weights\n",
    "    grads = torch.cat([g.reshape(-1) for g in grads])\n",
    "    print(grads.size())\n",
    "    # Create a vector of ones with the same size as the gradients\n",
    "    v = torch.ones(grads.size())#.to(grads.device)\n",
    "    # Compute the Hessian-vector product\n",
    "    Hv = torch.autograd.grad(grads, [p for p in model.parameters() if p.requires_grad], grad_outputs=v, retain_graph=True)\n",
    "    # Concatenate the Hessian-vector product into a single vector\n",
    "    Hv = torch.cat([h.reshape(-1) for h in Hv])\n",
    "    # Compute the maximum eigenvalue using the power iteration method\n",
    "    for _ in range(100):\n",
    "        v = Hv / torch.norm(Hv)\n",
    "        Hv = torch.autograd.grad(grads, model.parameters(), grad_outputs=v, retain_graph=True)\n",
    "        Hv = torch.cat([h.reshape(-1) for h in Hv])\n",
    "\n",
    "    return (v * Hv).sum()\n",
    "\n",
    "# correct this code to get rid of the error RuntimeError: reshape size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
    "def max_eigenvalue_corrected(model, loss_fn, data, target):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Create a variable from the data\n",
    "    data = torch.autograd.Variable(data, requires_grad=True)\n",
    "    # Compute the loss\n",
    "    loss = loss_fn(model(data), target)\n",
    "    # Compute the gradients\n",
    "    grads = torch.autograd.grad(\n",
    "            loss,\n",
    "            [p for p in model.parameters() if p.requires_grad],\n",
    "            retain_graph=True,\n",
    "            create_graph=True)\n",
    "    # Get the gradients of the weights\n",
    "    grads = torch.cat([g.reshape(-1) for g in grads])\n",
    "    # Create a vector of ones with the same size as the gradients\n",
    "    v = torch.ones(grads.size()).to(grads.device)\n",
    "    # Compute the Hessian-vector product\n",
    "    Hv = torch.autograd.grad(grads, [p for p in model.parameters() if p.requires_grad], grad_outputs=v, retain_graph=True)\n",
    "    # Concatenate the Hessian-vector product into a single vector\n",
    "    Hv = torch.cat([h.reshape(-1) for h in Hv])\n",
    "    # Compute the maximum eigenvalue using the power iteration method\n",
    "    for _ in range(100):\n",
    "        v = Hv / torch.norm(Hv)\n",
    "        Hv = torch.autograd.grad(grads, model.parameters(), grad_outputs=v, retain_graph=True)\n",
    "        Hv = torch.cat([h.reshape(-1) for h in Hv])\n",
    "\n",
    "    return (v * Hv).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b80f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self, layers_dim: List[int]):\n",
    "        super().__init__()\n",
    "        self.blocks = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(torch.nn.Conv2d(layer_dim1, layer_dim2, 3, padding=1),\n",
    "                                torch.nn.ReLU(),\n",
    "                                torch.nn.Conv2d(layer_dim2, layer_dim2, 3, padding=1, stride=2),\n",
    "                                torch.nn.ReLU(),\n",
    "                                # torch.nn.MaxPool2d(2, 2)\n",
    "                                )\n",
    "            for layer_dim1, layer_dim2 in zip(layers_dim[:-3], layers_dim[1:-2])\n",
    "        ])\n",
    "        # flatten_dim = infer_flatten_dim(conv_params, layers_dim[-3])\n",
    "        # napisz wnioskowanie sp≈Çaszczonego wymiaru\n",
    "        self.final_layer = torch.nn.Sequential(torch.nn.Linear(4096, layers_dim[-2]), torch.nn.ReLU(),\n",
    "                                               torch.nn.Linear(layers_dim[-2], layers_dim[-1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.final_layer(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, layers_dim):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(torch.nn.Linear(hidden_dim1, hidden_dim2), torch.nn.ReLU())\n",
    "            for hidden_dim1, hidden_dim2 in zip(layers_dim[:-2], layers_dim[1:-1])\n",
    "        ])\n",
    "        self.final_layer = torch.nn.Linear(layers_dim[-2], layers_dim[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b17eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN([3, 32, 64, 128, 10])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313018c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN([3, 32, 64, 128, 10])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ab465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=os.environ['CIFAR10_PATH'], train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "model = SimpleCNN([3, 32, 64, 128, 10])\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "x_true, y_true = next(iter(trainloader))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61bc6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim.zero_grad()\n",
    "max_eigenvalue_corrected(model, criterion, x_true, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c152a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.grad.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5069e8e",
   "metadata": {},
   "source": [
    "Brurrin images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e7c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94ca4e7e",
   "metadata": {},
   "source": [
    "Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2988f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = (0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.262)\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomAffine(degrees=0, translate=(1/8, 1/8)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=os.environ['CIFAR10_PATH'], train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c10c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52aeac8b",
   "metadata": {},
   "source": [
    "Blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de4334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import InterpolationMode\n",
    "down_to = 16\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(down_to, interpolation=InterpolationMode.BILINEAR, antialias=None),\n",
    "        transforms.Resize(32, interpolation=InterpolationMode.BILINEAR, antialias=None), \n",
    "        transforms.RandomAffine(degrees=0, translate=(1/8, 1/8)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Resize(down_to, interpolation=InterpolationMode.BILINEAR, antialias=True), transforms.Resize(32, interpolation=InterpolationMode.BILINEAR, antialias=True), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=os.environ['CIFAR10_PATH'], train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a0577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "243f8b011ad7363224c88ece0c506edda35d3eb613ddf3f3c8f81b41808ac438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
